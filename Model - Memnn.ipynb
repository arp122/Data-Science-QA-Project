{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate\n",
    "from keras.layers import LSTM\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab = ['.', '?', 'Bill', 'Fred', 'Jeff', 'Mary', 'What', 'Who', 'apple', 'did', 'football', 'gave', 'give', 'handed', 'milk', 'passed', 'received', 'the', 'to']\n",
      "x.shape = (1000, 7)\n",
      "xq.shape = (1000, 8)\n",
      "y.shape = (1000,)\n",
      "story_maxlen, query_maxlen = 7, 8\n"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "def tokenize(sent):\n",
    "    token = []\n",
    "    for x in re.split('(\\W+)?', sent):\n",
    "        if x.strip():\n",
    "            token.append(x.strip())\n",
    "    return token\n",
    "\n",
    "def parse_stories(lines,only_supporting=False):\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        nid = int(nid)\n",
    "        if nid == 1:\n",
    "            story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            if only_supporting:\n",
    "                # Only select the related substory\n",
    "                supporting = map(int, supporting.split())\n",
    "                substory = [story[i - 1] for i in supporting]\n",
    "            else:\n",
    "                # Provide all the substories\n",
    "                substory = [x for x in story if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else:\n",
    "            sent = tokenize(line)\n",
    "            story.append(sent)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(file,only_supporting=False):\n",
    "    data = parse_stories(file.readlines(),only_supporting)\n",
    "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
    "    \n",
    "    temp_data = []\n",
    "    for story, q, answer in data:\n",
    "        temp_data.append((flatten(story), q, answer))\n",
    "    return temp_data\n",
    "\n",
    "\n",
    "def vectorize_stories(data):\n",
    "    inputs, queries, answers = [], [], []\n",
    "    for story, query, answer in data:\n",
    "        inputs.append([word_idx[w] for w in story])\n",
    "        queries.append([word_idx[w] for w in query])\n",
    "        answers.append(word_idx[answer])\n",
    "    return (pad_sequences(inputs, maxlen=story_maxlen),\n",
    "            pad_sequences(queries, maxlen=query_maxlen),\n",
    "            np.array(answers))\n",
    "\n",
    "# Download the dataset\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "\n",
    "\n",
    "task = 'tasks_1-20_v1-2/en/qa5_three-arg-relations_{}.txt'\n",
    "\n",
    "with tarfile.open(path) as tar:\n",
    "    train_stories = get_stories(tar.extractfile(task.format('train')),only_supporting=True)\n",
    "    test_stories = get_stories(tar.extractfile(task.format('test')),only_supporting=True)\n",
    "\n",
    "    \n",
    "vocab = set()\n",
    "for story, q, answer in train_stories + test_stories:\n",
    "    vocab |= set(story + q + [answer])\n",
    "vocab = sorted(vocab)\n",
    "\n",
    "\n",
    "vocab_size = len(vocab) + 1\n",
    "\n",
    "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
    "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))\n",
    "\n",
    "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories)\n",
    "\n",
    "print('vocab = {}'.format(vocab))\n",
    "print('x.shape = {}'.format(inputs_train.shape))\n",
    "print('xq.shape = {}'.format(queries_train.shape))\n",
    "print('y.shape = {}'.format(answers_train.shape))\n",
    "print('story_maxlen, query_maxlen = {}, {}'.format(story_maxlen, query_maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 2.8547 - acc: 0.1570 - val_loss: 2.5413 - val_acc: 0.1880\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 0s 493us/step - loss: 2.1521 - acc: 0.1970 - val_loss: 1.6843 - val_acc: 0.2890\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 0s 478us/step - loss: 1.6049 - acc: 0.2770 - val_loss: 1.3796 - val_acc: 0.3330\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 0s 493us/step - loss: 1.4495 - acc: 0.2960 - val_loss: 1.3361 - val_acc: 0.3330\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 0s 496us/step - loss: 1.4282 - acc: 0.2930 - val_loss: 1.3239 - val_acc: 0.3520\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 0s 478us/step - loss: 1.3945 - acc: 0.3100 - val_loss: 1.3193 - val_acc: 0.3060\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 1s 661us/step - loss: 1.3774 - acc: 0.2860 - val_loss: 1.3095 - val_acc: 0.2890\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 1s 508us/step - loss: 1.3821 - acc: 0.2970 - val_loss: 1.2934 - val_acc: 0.4360\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 1s 535us/step - loss: 1.3353 - acc: 0.3610 - val_loss: 1.2714 - val_acc: 0.4260\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 0s 450us/step - loss: 1.2978 - acc: 0.3750 - val_loss: 1.2147 - val_acc: 0.4370\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 0s 468us/step - loss: 1.2071 - acc: 0.4400 - val_loss: 1.1213 - val_acc: 0.4760\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 0s 479us/step - loss: 1.1036 - acc: 0.5190 - val_loss: 1.0357 - val_acc: 0.5550\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 0s 451us/step - loss: 1.0321 - acc: 0.5310 - val_loss: 0.9770 - val_acc: 0.5890\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 0s 449us/step - loss: 0.9777 - acc: 0.5660 - val_loss: 0.9165 - val_acc: 0.6350\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 0s 458us/step - loss: 0.8819 - acc: 0.6250 - val_loss: 0.8445 - val_acc: 0.6990\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 0s 457us/step - loss: 0.8760 - acc: 0.6320 - val_loss: 0.8174 - val_acc: 0.6910\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 1s 576us/step - loss: 0.8236 - acc: 0.6430 - val_loss: 0.7881 - val_acc: 0.7070\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 1s 548us/step - loss: 0.7961 - acc: 0.6620 - val_loss: 0.7535 - val_acc: 0.6810\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 1s 568us/step - loss: 0.7869 - acc: 0.6540 - val_loss: 0.7396 - val_acc: 0.7020\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.7772 - acc: 0.6700 - val_loss: 0.7203 - val_acc: 0.7170\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.7428 - acc: 0.6860 - val_loss: 0.6868 - val_acc: 0.7320\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 1s 542us/step - loss: 0.7071 - acc: 0.7110 - val_loss: 0.6743 - val_acc: 0.7770\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 0s 492us/step - loss: 0.6800 - acc: 0.7220 - val_loss: 0.6289 - val_acc: 0.7680\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 1s 575us/step - loss: 0.6676 - acc: 0.7150 - val_loss: 0.6093 - val_acc: 0.7540\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 0s 435us/step - loss: 0.6265 - acc: 0.7560 - val_loss: 0.5888 - val_acc: 0.8040\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 1s 523us/step - loss: 0.6342 - acc: 0.7440 - val_loss: 0.5642 - val_acc: 0.7930\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 0s 439us/step - loss: 0.5939 - acc: 0.7560 - val_loss: 0.5444 - val_acc: 0.8180\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 0s 438us/step - loss: 0.5836 - acc: 0.7620 - val_loss: 0.5192 - val_acc: 0.8260\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 0s 448us/step - loss: 0.5633 - acc: 0.7740 - val_loss: 0.5035 - val_acc: 0.8450\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 0s 456us/step - loss: 0.5274 - acc: 0.7740 - val_loss: 0.4726 - val_acc: 0.8370\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 0s 482us/step - loss: 0.5147 - acc: 0.7910 - val_loss: 0.4570 - val_acc: 0.8530\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 0.4827 - acc: 0.8120 - val_loss: 0.4292 - val_acc: 0.8690\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 0s 482us/step - loss: 0.4581 - acc: 0.8250 - val_loss: 0.4020 - val_acc: 0.8690\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 0s 465us/step - loss: 0.4253 - acc: 0.8470 - val_loss: 0.3760 - val_acc: 0.8690\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 0s 432us/step - loss: 0.4240 - acc: 0.8290 - val_loss: 0.3538 - val_acc: 0.8700\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 0s 441us/step - loss: 0.3933 - acc: 0.8610 - val_loss: 0.3318 - val_acc: 0.8790\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 0s 434us/step - loss: 0.3806 - acc: 0.8450 - val_loss: 0.3158 - val_acc: 0.8800\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 0s 435us/step - loss: 0.3566 - acc: 0.8670 - val_loss: 0.2864 - val_acc: 0.8840\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 0s 428us/step - loss: 0.3362 - acc: 0.8830 - val_loss: 0.2543 - val_acc: 0.8840\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 0s 460us/step - loss: 0.3268 - acc: 0.8790 - val_loss: 0.2364 - val_acc: 0.8860\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.2845 - acc: 0.9110 - val_loss: 0.2170 - val_acc: 0.9260\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.2765 - acc: 0.9040 - val_loss: 0.1950 - val_acc: 0.9870\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 0s 457us/step - loss: 0.2577 - acc: 0.9200 - val_loss: 0.1730 - val_acc: 0.9660\n",
      "Epoch 44/100\n",
      "1000/1000 [==============================] - 0s 463us/step - loss: 0.2592 - acc: 0.9270 - val_loss: 0.1552 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 0s 484us/step - loss: 0.2185 - acc: 0.9470 - val_loss: 0.1347 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 1s 564us/step - loss: 0.2088 - acc: 0.9460 - val_loss: 0.1158 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 1s 536us/step - loss: 0.1839 - acc: 0.9640 - val_loss: 0.0984 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 1s 620us/step - loss: 0.1723 - acc: 0.9710 - val_loss: 0.0851 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 1s 526us/step - loss: 0.1615 - acc: 0.9690 - val_loss: 0.0768 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.1392 - acc: 0.9750 - val_loss: 0.0600 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 1s 623us/step - loss: 0.1412 - acc: 0.9770 - val_loss: 0.0547 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 1s 573us/step - loss: 0.1227 - acc: 0.9830 - val_loss: 0.0472 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 1s 532us/step - loss: 0.1280 - acc: 0.9760 - val_loss: 0.0427 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 0s 475us/step - loss: 0.1091 - acc: 0.9780 - val_loss: 0.0371 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 0s 467us/step - loss: 0.1064 - acc: 0.9800 - val_loss: 0.0328 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "1000/1000 [==============================] - 0s 486us/step - loss: 0.1165 - acc: 0.9740 - val_loss: 0.0327 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 0.0978 - acc: 0.9850 - val_loss: 0.0308 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "1000/1000 [==============================] - 0s 466us/step - loss: 0.1101 - acc: 0.9830 - val_loss: 0.0294 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "1000/1000 [==============================] - 0s 499us/step - loss: 0.0914 - acc: 0.9840 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0911 - acc: 0.9850 - val_loss: 0.0226 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "1000/1000 [==============================] - 0s 491us/step - loss: 0.0884 - acc: 0.9860 - val_loss: 0.0217 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "1000/1000 [==============================] - 0s 474us/step - loss: 0.0871 - acc: 0.9870 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "1000/1000 [==============================] - 0s 475us/step - loss: 0.0798 - acc: 0.9850 - val_loss: 0.0183 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "1000/1000 [==============================] - 0s 486us/step - loss: 0.0888 - acc: 0.9860 - val_loss: 0.0180 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "1000/1000 [==============================] - 1s 527us/step - loss: 0.0678 - acc: 0.9950 - val_loss: 0.0155 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "1000/1000 [==============================] - 1s 528us/step - loss: 0.0548 - acc: 0.9940 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "1000/1000 [==============================] - 1s 554us/step - loss: 0.0602 - acc: 0.9900 - val_loss: 0.0139 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "1000/1000 [==============================] - 1s 650us/step - loss: 0.0539 - acc: 0.9920 - val_loss: 0.0119 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "1000/1000 [==============================] - 1s 672us/step - loss: 0.0528 - acc: 0.9930 - val_loss: 0.0113 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "1000/1000 [==============================] - 1s 540us/step - loss: 0.0615 - acc: 0.9920 - val_loss: 0.0114 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "1000/1000 [==============================] - 1s 519us/step - loss: 0.0596 - acc: 0.9930 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "1000/1000 [==============================] - 0s 494us/step - loss: 0.0557 - acc: 0.9930 - val_loss: 0.0091 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "1000/1000 [==============================] - 0s 475us/step - loss: 0.0552 - acc: 0.9910 - val_loss: 0.0093 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "1000/1000 [==============================] - 0s 483us/step - loss: 0.0610 - acc: 0.9880 - val_loss: 0.0095 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0490 - acc: 0.9930 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "1000/1000 [==============================] - 0s 495us/step - loss: 0.0418 - acc: 0.9940 - val_loss: 0.0072 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "1000/1000 [==============================] - 0s 497us/step - loss: 0.0460 - acc: 0.9950 - val_loss: 0.0079 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "1000/1000 [==============================] - 0s 472us/step - loss: 0.0547 - acc: 0.9890 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "1000/1000 [==============================] - 0s 488us/step - loss: 0.0367 - acc: 0.9970 - val_loss: 0.0062 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "1000/1000 [==============================] - 0s 492us/step - loss: 0.0398 - acc: 0.9960 - val_loss: 0.0070 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "1000/1000 [==============================] - 1s 506us/step - loss: 0.0422 - acc: 0.9970 - val_loss: 0.0054 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "1000/1000 [==============================] - 0s 496us/step - loss: 0.0298 - acc: 0.9970 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "1000/1000 [==============================] - 1s 511us/step - loss: 0.0357 - acc: 0.9940 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "1000/1000 [==============================] - 0s 465us/step - loss: 0.0325 - acc: 0.9970 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "1000/1000 [==============================] - 1s 503us/step - loss: 0.0325 - acc: 0.9970 - val_loss: 0.0049 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "1000/1000 [==============================] - 0s 467us/step - loss: 0.0413 - acc: 0.9940 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "1000/1000 [==============================] - 1s 509us/step - loss: 0.0318 - acc: 0.9940 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "1000/1000 [==============================] - 0s 478us/step - loss: 0.0285 - acc: 0.9970 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "1000/1000 [==============================] - 1s 504us/step - loss: 0.0298 - acc: 0.9990 - val_loss: 0.0038 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "1000/1000 [==============================] - 0s 472us/step - loss: 0.0304 - acc: 0.9960 - val_loss: 0.0039 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "1000/1000 [==============================] - 0s 485us/step - loss: 0.0267 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "1000/1000 [==============================] - 0s 485us/step - loss: 0.0290 - acc: 0.9970 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "1000/1000 [==============================] - 0s 481us/step - loss: 0.0333 - acc: 0.9950 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "1000/1000 [==============================] - 0s 470us/step - loss: 0.0231 - acc: 0.9970 - val_loss: 0.0030 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "1000/1000 [==============================] - 1s 505us/step - loss: 0.0320 - acc: 0.9940 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "1000/1000 [==============================] - 0s 478us/step - loss: 0.0319 - acc: 0.9940 - val_loss: 0.0029 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "1000/1000 [==============================] - 1s 507us/step - loss: 0.0259 - acc: 0.9980 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "1000/1000 [==============================] - 0s 496us/step - loss: 0.0269 - acc: 0.9970 - val_loss: 0.0025 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "1000/1000 [==============================] - 0s 494us/step - loss: 0.0282 - acc: 0.9980 - val_loss: 0.0024 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "1000/1000 [==============================] - 0s 489us/step - loss: 0.0294 - acc: 0.9970 - val_loss: 0.0025 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1218bab38>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input_sequence = Input((story_maxlen,))\n",
    "question = Input((query_maxlen,))\n",
    "\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
    "                              output_dim=query_maxlen))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=query_maxlen))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)\n",
    "\n",
    "\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)\n",
    "\n",
    "\n",
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2, 1))(response)\n",
    "\n",
    "\n",
    "answer = concatenate([response, question_encoded])\n",
    "\n",
    "answer = LSTM(32)(answer)\n",
    "\n",
    "\n",
    "answer = Dropout(0.3)(answer)\n",
    "answer = Dense(vocab_size)(answer)\n",
    "\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit([inputs_train, queries_train], answers_train,\n",
    "          batch_size=32,\n",
    "          epochs=100,\n",
    "          validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxToWord = {}\n",
    "for key,value in word_idx.items():\n",
    "    idxToWord[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_values = model.predict([inputs_test, queries_test])\n",
    "predicted=[]\n",
    "true=[]\n",
    "for i in range(predicted_values.shape[0]):\n",
    "    predicted.append(idxToWord[np.argmax(predicted_values[i])])\n",
    "    true.append(idxToWord[answers_test[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAHmCAYAAADeNpzaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLbfpwLAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x123d57ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(predicted,true)\n",
    "cm.plot(normalized=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_loss: 4.9372 - val_acc: 0.5340 EPOCH 500 - NonSupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_loss: 2.4631 - val_acc: 0.5230 EPOCH 100 - NonSupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_loss: 1.2375 - val_acc: 0.4900 EPOCH 40 - NonSupport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_loss: 0.5266 - val_acc: 0.8010 EPOCH 40 - Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_loss: 0.0029 - val_acc: 1.0000 EPOCH 100 - Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#val_loss: 1.9073e-06 - val_acc: 1.0000 EPOCH 500 - Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
