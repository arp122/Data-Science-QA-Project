{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import urllib\n",
    "import sys\n",
    "import os\n",
    "import zipfile\n",
    "import tarfile\n",
    "import json \n",
    "import hashlib\n",
    "import re\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_zip_file = \"glove.6B.zip\"\n",
    "glove_vectors_file = \"glove.6B.50d.txt\"\n",
    "\n",
    "# 15 MB\n",
    "data_set_zip = \"tasks_1-20_v1-2.tar.gz\"\n",
    "\n",
    "#Select \"task 5\"\n",
    "train_set_file = \"qa5_three-arg-relations_train.txt\"\n",
    "test_set_file = \"qa5_three-arg-relations_test.txt\"\n",
    "\n",
    "train_set_post_file = \"tasks_1-20_v1-2/en/\"+train_set_file\n",
    "test_set_post_file = \"tasks_1-20_v1-2/en/\"+test_set_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try: from urllib.request import urlretrieve, urlopen\n",
    "except ImportError: \n",
    "    from urllib import urlretrieve\n",
    "    from urllib2 import urlopen\n",
    "if (not os.path.isfile(glove_zip_file) and\n",
    "    not os.path.isfile(glove_vectors_file)):\n",
    "    urlretrieve (\"http://nlp.stanford.edu/data/glove.6B.zip\", \n",
    "                 glove_zip_file)\n",
    "if (not os.path.isfile(data_set_zip) and\n",
    "    not (os.path.isfile(train_set_file) and os.path.isfile(test_set_file))):\n",
    "    urlretrieve (\"https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\", \n",
    "                 data_set_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unzip_single_file(zip_file_name, output_file_name):\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with open(output_file_name, 'wb') as out_file:\n",
    "            with zipfile.ZipFile(zip_file_name) as zipped:\n",
    "                for info in zipped.infolist():\n",
    "                    if output_file_name in info.filename:\n",
    "                        with zipped.open(info) as requested_file:\n",
    "                            out_file.write(requested_file.read())\n",
    "                            return\n",
    "def targz_unzip_single_file(zip_file_name, output_file_name, interior_relative_path):\n",
    "    if not os.path.isfile(output_file_name):\n",
    "        with tarfile.open(zip_file_name) as un_zipped:\n",
    "            un_zipped.extract(interior_relative_path+output_file_name)    \n",
    "unzip_single_file(glove_zip_file, glove_vectors_file)\n",
    "targz_unzip_single_file(data_set_zip, train_set_file, \"tasks_1-20_v1-2/en/\")\n",
    "targz_unzip_single_file(data_set_zip, test_set_file, \"tasks_1-20_v1-2/en/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_wordmap = {}\n",
    "with open(glove_vectors_file, \"r\", encoding=\"utf8\") as glove:\n",
    "    for line in glove:\n",
    "        name, vector = tuple(line.split(\" \", 1))\n",
    "        glove_wordmap[name] = np.fromstring(vector, sep=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wvecs = []\n",
    "for item in glove_wordmap.items():\n",
    "    wvecs.append(item[1])\n",
    "s = np.vstack(wvecs)\n",
    "\n",
    "v = np.var(s,0) \n",
    "m = np.mean(s,0) \n",
    "RS = np.random.RandomState()\n",
    "\n",
    "def fill_unk(unk):\n",
    "    global glove_wordmap\n",
    "    glove_wordmap[unk] = RS.multivariate_normal(m,np.diag(v))\n",
    "    return glove_wordmap[unk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence2sequence(sentence):\n",
    "    tokens = sentence.strip('\"(),-').lower().split(\" \")\n",
    "    rows = []\n",
    "    words = []\n",
    "    for token in tokens:\n",
    "        i = len(token)\n",
    "        while len(token) > 0:\n",
    "            word = token[:i]\n",
    "            if word in glove_wordmap:\n",
    "                rows.append(glove_wordmap[word])\n",
    "                words.append(word)\n",
    "                token = token[i:]\n",
    "                i = len(token)\n",
    "                continue\n",
    "            else:\n",
    "                i = i-1\n",
    "            if i == 0:\n",
    "                rows.append(fill_unk(token))\n",
    "                words.append(token)\n",
    "                break\n",
    "    return np.array(rows), words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contextualize(set_file):\n",
    "    data = []\n",
    "    context = []\n",
    "    with open(set_file, \"r\", encoding=\"utf8\") as train:\n",
    "        for line in train:\n",
    "            l, ine = tuple(line.split(\" \", 1))\n",
    "            if l is \"1\":\n",
    "                context = []\n",
    "            if \"\\t\" in ine: \n",
    "                question, answer, support = tuple(ine.split(\"\\t\"))\n",
    "                data.append((tuple(zip(*context))+\n",
    "                             sentence2sequence(question)+\n",
    "                             sentence2sequence(answer)+\n",
    "                             ([int(s) for s in support.split()],)))\n",
    "            else:\n",
    "                context.append(sentence2sequence(ine[:-1]))\n",
    "    return data\n",
    "train_data = contextualize(train_set_post_file)\n",
    "test_data = contextualize(test_set_post_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_train_data = []\n",
    "def finalize(data):\n",
    "    final_data = []\n",
    "    for cqas in train_data:\n",
    "        contextvs, contextws, qvs, qws, avs, aws, spt = cqas\n",
    "\n",
    "        lengths = itertools.accumulate(len(cvec) for cvec in contextvs)\n",
    "        context_vec = np.concatenate(contextvs)\n",
    "        context_words = sum(contextws,[])\n",
    "\n",
    "        sentence_ends = np.array(list(lengths)) \n",
    "        final_data.append((context_vec, sentence_ends, qvs, spt, context_words, cqas, avs, aws))\n",
    "    return np.array(final_data)\n",
    "final_train_data = finalize(train_data)   \n",
    "final_test_data = finalize(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recurrent_cell_size = 128\n",
    "D = 50 \n",
    "learning_rate = 0.005\n",
    "input_p, output_p = 0.5, 0.5\n",
    "batch_size = 128\n",
    "passes = 4\n",
    "ff_hidden_size = 256\n",
    "weight_decay = 0.00000001\n",
    "training_iterations_count = 400000\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = tf.placeholder(tf.float32, [None, None, D], \"context\")  \n",
    "context_placeholder = context\n",
    "\n",
    "input_sentence_endings = tf.placeholder(tf.int32, [None, None, 2], \"sentence\")\n",
    "\n",
    "input_gru = tf.contrib.rnn.GRUCell(recurrent_cell_size)\n",
    "\n",
    "gru_drop = tf.contrib.rnn.DropoutWrapper(input_gru, input_p, output_p)\n",
    "\n",
    "input_module_outputs, _ = tf.nn.dynamic_rnn(gru_drop, context, dtype=tf.float32, scope = \"input_module\")\n",
    "\n",
    "cs = tf.gather_nd(input_module_outputs, input_sentence_endings)\n",
    "s = input_module_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = tf.placeholder(tf.float32, [None, None, D], \"query\")\n",
    "input_query_lengths = tf.placeholder(tf.int32, [None, 2], \"query_lengths\")\n",
    "\n",
    "question_module_outputs, _ = tf.nn.dynamic_rnn(gru_drop, query, dtype=tf.float32, \n",
    "                                               scope = tf.VariableScope(True, \"input_module\"))\n",
    "\n",
    "q = tf.gather_nd(question_module_outputs, input_query_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = tf.stack([tf.constant(1),tf.shape(cs)[1], tf.constant(1)])\n",
    "re_q = tf.tile(tf.reshape(q,[-1,1,recurrent_cell_size]),size)\n",
    "\n",
    "\n",
    "output_size = 1 \n",
    "\n",
    "attend_init = tf.random_normal_initializer(stddev=0.1)\n",
    "w_1 = tf.get_variable(\"attend_w1\", [1,recurrent_cell_size*7, recurrent_cell_size], \n",
    "                      tf.float32, initializer = attend_init)\n",
    "w_2 = tf.get_variable(\"attend_w2\", [1,recurrent_cell_size, output_size], \n",
    "                      tf.float32, initializer = attend_init)\n",
    "\n",
    "b_1 = tf.get_variable(\"attend_b1\", [1, recurrent_cell_size], \n",
    "                      tf.float32, initializer = attend_init)\n",
    "b_2 = tf.get_variable(\"attend_b2\", [1, output_size], \n",
    "                      tf.float32, initializer = attend_init)\n",
    "\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(w_1))\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(b_1))\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(w_2))\n",
    "tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, tf.nn.l2_loss(b_2))\n",
    "\n",
    "def attention(c, mem, existing_facts):\n",
    "    with tf.variable_scope(\"attending\") as scope:\n",
    "        attending = tf.concat([c, mem, re_q, c * re_q,  c * mem, (c-re_q)**2, (c-mem)**2], 2)\n",
    "\n",
    "        m1 = tf.matmul(attending * existing_facts, \n",
    "                       tf.tile(w_1, tf.stack([tf.shape(attending)[0],1,1]))) * existing_facts\n",
    "        \n",
    "        bias_1 = b_1 * existing_facts\n",
    "\n",
    "        tnhan = tf.nn.relu(m1 + bias_1)\n",
    "\n",
    "        m2 = tf.matmul(tnhan, tf.tile(w_2, tf.stack([tf.shape(attending)[0],1,1])))\n",
    "\n",
    "        bias_2 = b_2 * existing_facts\n",
    "\n",
    "        norm_m2 = tf.nn.l2_normalize(m2 + bias_2, -1)\n",
    "\n",
    "        softmax_idx = tf.where(tf.not_equal(norm_m2, 0))[:,:-1]\n",
    "        softmax_gather = tf.gather_nd(norm_m2[...,0], softmax_idx)\n",
    "        softmax_shape = tf.shape(norm_m2, out_type=tf.int64)[:-1]\n",
    "        softmaxable = tf.SparseTensor(softmax_idx, softmax_gather, softmax_shape)\n",
    "        return tf.expand_dims(tf.sparse_tensor_to_dense(tf.sparse_softmax(softmaxable)),-1)\n",
    "\n",
    "facts_0s = tf.cast(tf.count_nonzero(input_sentence_endings[:,:,-1:],-1,keep_dims=True),tf.float32)\n",
    "\n",
    "\n",
    "with tf.variable_scope(\"Episodes\") as scope:\n",
    "    attention_gru = tf.contrib.rnn.GRUCell(recurrent_cell_size)\n",
    "\n",
    "    memory = [q]\n",
    "\n",
    "    attends = []\n",
    "    for a in range(passes):\n",
    "        attend_to = attention(cs, tf.tile(tf.reshape(memory[-1],[-1,1,recurrent_cell_size]),size),\n",
    "                              facts_0s)\n",
    "\n",
    "        retain = 1-attend_to\n",
    "\n",
    "        while_valid_index = (lambda state, index: index < tf.shape(cs)[1])\n",
    "        update_state = (lambda state, index: (attend_to[:,index,:] * \n",
    "                                                 attention_gru(cs[:,index,:], state)[0] + \n",
    "                                                 retain[:,index,:] * state))\n",
    "        memory.append(tuple(tf.while_loop(while_valid_index,\n",
    "                          (lambda state, index: (update_state(state,index),index+1)),\n",
    "                           loop_vars = [memory[-1], 0]))[0]) \n",
    "\n",
    "        attends.append(attend_to)\n",
    "\n",
    "        scope.reuse_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a0 = tf.concat([memory[-1], q], -1)\n",
    "\n",
    "fc_init = tf.random_normal_initializer(stddev=0.1) \n",
    "\n",
    "with tf.variable_scope(\"answer\"):\n",
    "    w_answer = tf.get_variable(\"weight\", [recurrent_cell_size*2, D], \n",
    "                               tf.float32, initializer = fc_init)\n",
    "    tf.add_to_collection(tf.GraphKeys.REGULARIZATION_LOSSES, \n",
    "                     tf.nn.l2_loss(w_answer)) \n",
    "\n",
    "    logit = tf.expand_dims(tf.matmul(a0, w_answer),1)\n",
    "\n",
    "    with tf.variable_scope(\"ending\"):\n",
    "        all_ends = tf.reshape(input_sentence_endings, [-1,2])\n",
    "        range_ends = tf.range(tf.shape(all_ends)[0])\n",
    "        ends_indices = tf.stack([all_ends[:,0],range_ends], axis=1)\n",
    "        ind = tf.reduce_max(tf.scatter_nd(ends_indices, all_ends[:,1],\n",
    "                                          [tf.shape(q)[0], tf.shape(all_ends)[0]]),\n",
    "                            axis=-1)\n",
    "        range_ind = tf.range(tf.shape(ind)[0])\n",
    "        mask_ends = tf.cast(tf.scatter_nd(tf.stack([ind, range_ind], axis=1), \n",
    "                                          tf.ones_like(range_ind), [tf.reduce_max(ind)+1, \n",
    "                                                                    tf.shape(ind)[0]]), bool)\n",
    "        mask = tf.scan(tf.logical_xor,mask_ends, tf.ones_like(range_ind, dtype=bool))\n",
    "\n",
    "    logits = -tf.reduce_sum(tf.square(context*tf.transpose(tf.expand_dims(\n",
    "                    tf.cast(mask, tf.float32),-1),[1,0,2]) - logit), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_standard = tf.placeholder(tf.float32, [None, 1, D], \"answer\")\n",
    "with tf.variable_scope('accuracy'):\n",
    "    eq = tf.equal(context, gold_standard)\n",
    "    corrbool = tf.reduce_all(eq,-1)\n",
    "    logloc = tf.reduce_max(logits, -1, keep_dims = True)\n",
    "    locs = tf.equal(logits, logloc)\n",
    "\n",
    "    correctsbool = tf.reduce_any(tf.logical_and(locs, corrbool), -1)\n",
    "    corrects = tf.where(correctsbool, tf.ones_like(correctsbool, dtype=tf.float32), \n",
    "                        tf.zeros_like(correctsbool,dtype=tf.float32))\n",
    "\n",
    "    corr = tf.where(corrbool, tf.ones_like(corrbool, dtype=tf.float32), \n",
    "                        tf.zeros_like(corrbool,dtype=tf.float32))\n",
    "with tf.variable_scope(\"loss\"):\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits = tf.nn.l2_normalize(logits,-1),\n",
    "                                                   labels = corr)\n",
    "\n",
    "    total_loss = tf.reduce_mean(loss) + weight_decay * tf.add_n(\n",
    "        tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "opt_op = optimizer.minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_batch(batch_data, more_data = False):\n",
    "    context_vec, sentence_ends, questionvs, spt, context_words, cqas, answervs, _ = zip(*batch_data)\n",
    "    ends = list(sentence_ends)\n",
    "    maxend = max(map(len, ends))\n",
    "    aends = np.zeros((len(ends), maxend))\n",
    "    for index, i in enumerate(ends):\n",
    "        for indexj, x in enumerate(i):\n",
    "            aends[index, indexj] = x-1\n",
    "    new_ends = np.zeros(aends.shape+(2,))\n",
    "\n",
    "    for index, x in np.ndenumerate(aends):\n",
    "        new_ends[index+(0,)] = index[0]\n",
    "        new_ends[index+(1,)] = x\n",
    "\n",
    "    contexts = list(context_vec)\n",
    "    max_context_length = max([len(x) for x in contexts])\n",
    "    contextsize = list(np.array(contexts[0]).shape)\n",
    "    contextsize[0] = max_context_length\n",
    "    final_contexts = np.zeros([len(contexts)]+contextsize)\n",
    "\n",
    "    contexts = [np.array(x) for x in contexts]\n",
    "    for i, context in enumerate(contexts):\n",
    "        final_contexts[i,0:len(context),:] = context\n",
    "    max_query_length = max(len(x) for x in questionvs)\n",
    "    querysize = list(np.array(questionvs[0]).shape)\n",
    "    querysize[:1] = [len(questionvs),max_query_length]\n",
    "    queries = np.zeros(querysize)\n",
    "    querylengths = np.array(list(zip(range(len(questionvs)),[len(q)-1 for q in questionvs])))\n",
    "    questions = [np.array(q) for q in questionvs]\n",
    "    for i, question in enumerate(questions):\n",
    "        queries[i,0:len(question),:] = question\n",
    "    data = {context_placeholder: final_contexts, input_sentence_endings: new_ends, \n",
    "                            query:queries, input_query_lengths:querylengths, gold_standard: answervs}\n",
    "    return (data, context_words, cqas) if more_data else data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3125 [00:48<42:24:33, 48.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0.0, Minibatch Loss=  0.6728524 Accuracy=  0.0953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 101/3125 [14:12<7:05:28,  8.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 100.0, Minibatch Loss=  0.6727554 Accuracy=  0.3671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 201/3125 [26:38<6:27:28,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 200.0, Minibatch Loss=  0.672751 Accuracy=  0.42421874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 301/3125 [38:13<5:58:37,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 300.0, Minibatch Loss=  0.6727286 Accuracy=  0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 401/3125 [48:52<5:31:58,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 400.0, Minibatch Loss=  0.6727315 Accuracy=  0.5625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 501/3125 [59:43<5:12:49,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 500.0, Minibatch Loss=  0.6727182 Accuracy=  0.6148437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 601/3125 [1:10:32<4:56:14,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 600.0, Minibatch Loss=  0.6727019 Accuracy=  0.6984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 701/3125 [1:20:23<4:38:00,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 700.0, Minibatch Loss=  0.67271155 Accuracy=  0.73125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 801/3125 [1:31:27<4:25:21,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 800.0, Minibatch Loss=  0.67268497 Accuracy=  0.76875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 901/3125 [1:42:31<4:13:03,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 900.0, Minibatch Loss=  0.6726597 Accuracy=  0.7835938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1001/3125 [1:54:13<4:02:21,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1000.0, Minibatch Loss=  0.6726565 Accuracy=  0.80078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 1101/3125 [12:37:25<23:12:24, 41.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1100.0, Minibatch Loss=  0.67262393 Accuracy=  0.821875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1201/3125 [12:48:31<20:31:10, 38.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1200.0, Minibatch Loss=  0.6726484 Accuracy=  0.83671874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1301/3125 [12:57:49<18:10:31, 35.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1300.0, Minibatch Loss=  0.67264616 Accuracy=  0.8648437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 1401/3125 [13:07:20<16:08:51, 33.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1400.0, Minibatch Loss=  0.67261076 Accuracy=  0.87421876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 1501/3125 [13:17:06<14:22:26, 31.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1500.0, Minibatch Loss=  0.6725826 Accuracy=  0.8851563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1601/3125 [13:27:03<12:48:14, 30.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1600.0, Minibatch Loss=  0.672601 Accuracy=  0.9078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 1701/3125 [13:36:43<11:23:43, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1700.0, Minibatch Loss=  0.67260927 Accuracy=  0.88125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 1801/3125 [13:48:59<10:09:25, 27.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1800.0, Minibatch Loss=  0.6726035 Accuracy=  0.89375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 1901/3125 [14:01:03<9:01:31, 26.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1900.0, Minibatch Loss=  0.6725866 Accuracy=  0.90546876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 2001/3125 [14:12:41<7:58:58, 25.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2000.0, Minibatch Loss=  0.6725823 Accuracy=  0.9171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2101/3125 [14:23:11<7:00:42, 24.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2100.0, Minibatch Loss=  0.67259485 Accuracy=  0.90625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 2201/3125 [14:33:45<6:06:48, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2200.0, Minibatch Loss=  0.67260253 Accuracy=  0.93046874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 2301/3125 [14:43:33<5:16:24, 23.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2300.0, Minibatch Loss=  0.67259663 Accuracy=  0.9195312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2401/3125 [14:53:15<4:29:21, 22.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2400.0, Minibatch Loss=  0.6725898 Accuracy=  0.92890626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 2501/3125 [15:02:40<3:45:13, 21.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2500.0, Minibatch Loss=  0.6725982 Accuracy=  0.9164063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 2601/3125 [15:12:32<3:03:50, 21.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2600.0, Minibatch Loss=  0.67258346 Accuracy=  0.9164063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 2701/3125 [16:30:53<2:35:32, 22.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2700.0, Minibatch Loss=  0.6725888 Accuracy=  0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 2801/3125 [16:42:27<1:55:57, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2800.0, Minibatch Loss=  0.6725905 Accuracy=  0.94453126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 2901/3125 [16:53:21<1:18:14, 20.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2900.0, Minibatch Loss=  0.672588 Accuracy=  0.909375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 3001/3125 [17:04:22<42:19, 20.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3000.0, Minibatch Loss=  0.6725935 Accuracy=  0.93046874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3101/3125 [17:14:41<08:00, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3100.0, Minibatch Loss=  0.67259914 Accuracy=  0.9203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3125/3125 [17:16:58<00:00, 19.91s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm_installed = False\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "    tqdm_installed = True\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "batch = np.random.randint(final_test_data.shape[0], size=batch_size*10)\n",
    "batch_data = final_test_data[batch]\n",
    "\n",
    "validation_set, val_context_words, val_cqas = prep_batch(batch_data, True)\n",
    "\n",
    "def train(iterations, batch_size):\n",
    "    training_iterations = range(0,iterations,batch_size)\n",
    "    if tqdm_installed:\n",
    "        training_iterations = tqdm(training_iterations)\n",
    "\n",
    "    wordz = []\n",
    "    for j in training_iterations:\n",
    "\n",
    "        batch = np.random.randint(final_train_data.shape[0], size=batch_size)\n",
    "        batch_data = final_train_data[batch]\n",
    "\n",
    "        sess.run([opt_op], feed_dict=prep_batch(batch_data))\n",
    "        if (j/batch_size) % display_step == 0:\n",
    "\n",
    "            acc, ccs, tmp_loss, log, con, cor, loc  = sess.run([corrects, cs, total_loss, logit,\n",
    "                                                                context_placeholder,corr, locs], \n",
    "                                                               feed_dict=validation_set)\n",
    "            print(\"Iter \" + str(j/batch_size) + \", Minibatch Loss= \",tmp_loss,\n",
    "                  \"Accuracy= \", np.mean(acc))\n",
    "train(400000,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.955\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(sess.run([corrects], feed_dict= prep_batch(final_test_data))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_val = []\n",
    "predicted_val = []\n",
    "\n",
    "indices = np.argmax(n,axis=1)\n",
    "\n",
    "\n",
    "indicesc = np.argmax(a,axis=1)\n",
    "\n",
    "for i,e,cw, cqa in list(zip(indices, indicesc, val_context_words, val_cqas)):\n",
    "    if cw[i] != 'picked':\n",
    "        true_val.append(cw[i])\n",
    "        predicted_val.append(cw[e])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAHmCAYAAADeNpzaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAQBEiAwAIEJkAAARIgMAiBAZAEDEC38IAchXMcH7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x131458ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = ConfusionMatrix(predicted_val,true_val)\n",
    "cm.plot(normalized=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
